{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(1, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 2)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tdYU9lpdL7AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the autoencoder model and set the loss function and optimizer\n",
        "model = Autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data/', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ])),\n",
        "    batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "a-_6Phu2L9dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.view(data.size(0), -1)\n",
        "        target=torch.tensor(target, dtype=torch.float32).view(data.size(0), -1)\n",
        "        outputs = model(target)\n",
        "        loss = criterion(outputs, data)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (batch_idx+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD6l6KzrL_f9",
        "outputId": "74379be9-c335-4291-862f-536884f150ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-90-312f04e2ac83>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target=torch.tensor(target, dtype=torch.float32).view(data.size(0), -1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/938], Loss: 0.0640\n",
            "Epoch [1/10], Step [200/938], Loss: 0.0619\n",
            "Epoch [1/10], Step [300/938], Loss: 0.0648\n",
            "Epoch [1/10], Step [400/938], Loss: 0.0603\n",
            "Epoch [1/10], Step [500/938], Loss: 0.0586\n",
            "Epoch [1/10], Step [600/938], Loss: 0.0590\n",
            "Epoch [1/10], Step [700/938], Loss: 0.0575\n",
            "Epoch [1/10], Step [800/938], Loss: 0.0572\n",
            "Epoch [1/10], Step [900/938], Loss: 0.0579\n",
            "Epoch [2/10], Step [100/938], Loss: 0.0555\n",
            "Epoch [2/10], Step [200/938], Loss: 0.0535\n",
            "Epoch [2/10], Step [300/938], Loss: 0.0577\n",
            "Epoch [2/10], Step [400/938], Loss: 0.0536\n",
            "Epoch [2/10], Step [500/938], Loss: 0.0574\n",
            "Epoch [2/10], Step [600/938], Loss: 0.0553\n",
            "Epoch [2/10], Step [700/938], Loss: 0.0523\n",
            "Epoch [2/10], Step [800/938], Loss: 0.0549\n",
            "Epoch [2/10], Step [900/938], Loss: 0.0544\n",
            "Epoch [3/10], Step [100/938], Loss: 0.0531\n",
            "Epoch [3/10], Step [200/938], Loss: 0.0593\n",
            "Epoch [3/10], Step [300/938], Loss: 0.0543\n",
            "Epoch [3/10], Step [400/938], Loss: 0.0528\n",
            "Epoch [3/10], Step [500/938], Loss: 0.0545\n",
            "Epoch [3/10], Step [600/938], Loss: 0.0584\n",
            "Epoch [3/10], Step [700/938], Loss: 0.0521\n",
            "Epoch [3/10], Step [800/938], Loss: 0.0561\n",
            "Epoch [3/10], Step [900/938], Loss: 0.0557\n",
            "Epoch [4/10], Step [100/938], Loss: 0.0552\n",
            "Epoch [4/10], Step [200/938], Loss: 0.0510\n",
            "Epoch [4/10], Step [300/938], Loss: 0.0544\n",
            "Epoch [4/10], Step [400/938], Loss: 0.0542\n",
            "Epoch [4/10], Step [500/938], Loss: 0.0554\n",
            "Epoch [4/10], Step [600/938], Loss: 0.0536\n",
            "Epoch [4/10], Step [700/938], Loss: 0.0534\n",
            "Epoch [4/10], Step [800/938], Loss: 0.0535\n",
            "Epoch [4/10], Step [900/938], Loss: 0.0549\n",
            "Epoch [5/10], Step [100/938], Loss: 0.0574\n",
            "Epoch [5/10], Step [200/938], Loss: 0.0491\n",
            "Epoch [5/10], Step [300/938], Loss: 0.0535\n",
            "Epoch [5/10], Step [400/938], Loss: 0.0506\n",
            "Epoch [5/10], Step [500/938], Loss: 0.0561\n",
            "Epoch [5/10], Step [600/938], Loss: 0.0515\n",
            "Epoch [5/10], Step [700/938], Loss: 0.0513\n",
            "Epoch [5/10], Step [800/938], Loss: 0.0569\n",
            "Epoch [5/10], Step [900/938], Loss: 0.0569\n",
            "Epoch [6/10], Step [100/938], Loss: 0.0545\n",
            "Epoch [6/10], Step [200/938], Loss: 0.0527\n",
            "Epoch [6/10], Step [300/938], Loss: 0.0553\n",
            "Epoch [6/10], Step [400/938], Loss: 0.0554\n",
            "Epoch [6/10], Step [500/938], Loss: 0.0518\n",
            "Epoch [6/10], Step [600/938], Loss: 0.0533\n",
            "Epoch [6/10], Step [700/938], Loss: 0.0557\n",
            "Epoch [6/10], Step [800/938], Loss: 0.0567\n",
            "Epoch [6/10], Step [900/938], Loss: 0.0516\n",
            "Epoch [7/10], Step [100/938], Loss: 0.0536\n",
            "Epoch [7/10], Step [200/938], Loss: 0.0518\n",
            "Epoch [7/10], Step [300/938], Loss: 0.0524\n",
            "Epoch [7/10], Step [400/938], Loss: 0.0523\n",
            "Epoch [7/10], Step [500/938], Loss: 0.0589\n",
            "Epoch [7/10], Step [600/938], Loss: 0.0537\n",
            "Epoch [7/10], Step [700/938], Loss: 0.0537\n",
            "Epoch [7/10], Step [800/938], Loss: 0.0561\n",
            "Epoch [7/10], Step [900/938], Loss: 0.0532\n",
            "Epoch [8/10], Step [100/938], Loss: 0.0532\n",
            "Epoch [8/10], Step [200/938], Loss: 0.0555\n",
            "Epoch [8/10], Step [300/938], Loss: 0.0523\n",
            "Epoch [8/10], Step [400/938], Loss: 0.0517\n",
            "Epoch [8/10], Step [500/938], Loss: 0.0558\n",
            "Epoch [8/10], Step [600/938], Loss: 0.0489\n",
            "Epoch [8/10], Step [700/938], Loss: 0.0533\n",
            "Epoch [8/10], Step [800/938], Loss: 0.0579\n",
            "Epoch [8/10], Step [900/938], Loss: 0.0488\n",
            "Epoch [9/10], Step [100/938], Loss: 0.0568\n",
            "Epoch [9/10], Step [200/938], Loss: 0.0534\n",
            "Epoch [9/10], Step [300/938], Loss: 0.0502\n",
            "Epoch [9/10], Step [400/938], Loss: 0.0530\n",
            "Epoch [9/10], Step [500/938], Loss: 0.0544\n",
            "Epoch [9/10], Step [600/938], Loss: 0.0518\n",
            "Epoch [9/10], Step [700/938], Loss: 0.0547\n",
            "Epoch [9/10], Step [800/938], Loss: 0.0587\n",
            "Epoch [9/10], Step [900/938], Loss: 0.0502\n",
            "Epoch [10/10], Step [100/938], Loss: 0.0548\n",
            "Epoch [10/10], Step [200/938], Loss: 0.0525\n",
            "Epoch [10/10], Step [300/938], Loss: 0.0552\n",
            "Epoch [10/10], Step [400/938], Loss: 0.0526\n",
            "Epoch [10/10], Step [500/938], Loss: 0.0570\n",
            "Epoch [10/10], Step [600/938], Loss: 0.0540\n",
            "Epoch [10/10], Step [700/938], Loss: 0.0567\n",
            "Epoch [10/10], Step [800/938], Loss: 0.0535\n",
            "Epoch [10/10], Step [900/938], Loss: 0.0510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a function to create input tensors\n",
        "def create_input(number):\n",
        "    # Load MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    dataset = datasets.MNIST(root='data/', train=True, transform=transform, download=True)\n",
        "\n",
        "    # Get the image corresponding to the number\n",
        "    index = dataset.targets == number\n",
        "    image = dataset.data[index][0]\n",
        "\n",
        "    # Create input tensor\n",
        "    input_tensor = torch.tensor(image, dtype=torch.float32).view(1, -1)\n",
        "    input_tensor = input_tensor.unsqueeze(0) # add a dimension to the tensor to match the input shape of the model\n",
        "    return input_tensor, torch.tensor([number], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "4xz3TKuKMBUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on a specific number\n",
        "input_tensor, target = create_input(0)\n",
        "print(target.shape)\n",
        "output_tensor = model(target).squeeze() # use the squeeze function to remove the extra dimension of the output tensor\n",
        "\n",
        "# Convert the output tensor to a numpy array and reshape it to an image format\n",
        "output_image = output_tensor.detach().numpy().reshape((28,28))\n",
        "\n",
        "# Plot the input and output images\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "ax[0].imshow(input_tensor.view(28, 28), cmap='gray')\n",
        "ax[0].set_title('Input Image')\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(output_image, cmap='gray')\n",
        "ax[1].set_title('Output Image')\n",
        "ax[1].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "ctDlBXWJQLA2",
        "outputId": "8ea35e09-354e-401d-be54-f96c54403e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-91-096d4bcce533>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_tensor = torch.tensor(image, dtype=torch.float32).view(1, -1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}